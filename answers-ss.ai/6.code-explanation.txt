{\rtf1\ansi\ansicpg1252\cocoartf2639
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;\f1\fnil\fcharset0 Menlo-Bold;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;\red200\green205\blue211;
\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c0\c1\c1;\cssrgb\c100000\c100000\c99985\c0;\cssrgb\c82383\c83963\c85905;
\cssrgb\c100000\c100000\c99941;\cssrgb\c0\c1\c1;\cssrgb\c100000\c100000\c99985\c0;}
\margl1440\margr1440\vieww17000\viewh13320\viewkind0
\deftab720
\pard\pardeftab720\sa400\partightenfactor0

\f0\fs32 \cf2 \cb3 \expnd0\expndtw0\kerning0
The provided code represents a real-time data processing system using Kafka, consisting of two applications: a Producer (
\f1\b\fs28 \cf2 \cb3 producer_app
\f0\b0\fs32 \cf2 \cb3  and 
\f1\b\fs28 \cf2 \cb3 Dockerfile-producer
\f0\b0\fs32 \cf2 \cb3 ) and a Consumer (
\f1\b\fs28 \cf2 \cb3 consumer_app
\f0\b0\fs32 \cf2 \cb3  and 
\f1\b\fs28 \cf2 \cb3 Dockerfile-consumer
\f0\b0\fs32 \cf2 \cb3 ).\
The Producer application connects to a Kafka broker hosted at 'kafka:9092' via Docker Compose. It initiates a connection and retries until it successfully establishes a connection with the Kafka broker. Once connected, it sends messages at one-second intervals, each message incremented in count. These messages are logged, and the Producer continues to send them as long as there is no interruption from the user.\
The Consumer application also connects to the same Kafka topic that the Producer writes to. It consumes these messages and logs them as, \cf6 \cb7 i.e. \cf2 \cb3 \'93Received message: 3". Additionally, the Consumer stores the messages in two data stores: Elasticsearch and Neo4j. In Elasticsearch, it indexes the messages and appends a timestamp to each one. In Neo4j, the Consumer inserts the messages as nodes labelled "Message" with a "content" property.\
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 Both the Producer and Consumer applications include error-handling mechanisms to manage potential connection issues with Kafka, Elasticsearch, and Neo4j. They are designed to retry connections to ensure the smooth flow of data processing.}